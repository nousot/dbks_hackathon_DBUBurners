{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3752250500.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    from typing\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "from langchain.document_loaders import PyPDFloader\n",
    "\n",
    "def load_pdfs(dir_path: str) -> Dict:\n",
    "    \n",
    "    file_contents = {}\n",
    "    files = [f for f in os.listdir(dir_path) if f.endswith('.pdf')]\n",
    "    for file in files:\n",
    "        loader = PyPDFloader(os.path.join(dir_path, file))\n",
    "        pages = loader.load_and_split()\n",
    "        \n",
    "        for page_counter, page in enumerate(pages):\n",
    "            file_contents[f'{file}_{page_counter}'] = page\n",
    "            \n",
    "    return file_contents\n",
    "        \n",
    "\n",
    "mining_qa_prompts = {\n",
    "  \"title\": \"Q&A Prompts: Discovering Rich Visual Clues through Mining Question-Answer Prompts for VQA Requiring Diverse World Knowledge\",\n",
    "  \"authors\": [\"Haibo Wang\", \"Weifeng Ge\", \"...\"],\n",
    "  \"affiliation\": \"School of Computer Science, Fudan University\",\n",
    "  \"focus\": \"Enhancing AI models for Visual Question Answering using Q&A Prompts method\",\n",
    "  \"methodology\": [\"Training a visual question generation model\", \"Generating question-answer prompts\", \"Reasoning with these prompts\"],\n",
    "  \"key_findings\": \"Improvement in AI's ability to answer complex visual questions with diverse world knowledge\",\n",
    "  \"publication_date\": \"2024-01-19\"\n",
    "}\n",
    "\n",
    "clinical_document_qa = {\n",
    "  \"title\": \"Dynamic Q&A of Clinical Documents with Large Language Models\",\n",
    "  \"authors\": [\"Ran Elgedawy\", \"Sudarshan Srinivasan\", \"Ioana Danciu\", \"...\"],\n",
    "  \"affiliation\": \"University of Tennessee Knoxville, Oak Ridge National Laboratory\",\n",
    "  \"focus\": \"Development of a conversational interface using LLMs for querying clinical notes\",\n",
    "  \"key_technologies\": [\"Large Language Models\", \"Semantic Embedding Models\"],\n",
    "  \"applications\": \"Efficient querying and retrieval in EHRs\",\n",
    "  \"challenges_future_work\": [\"Model optimization\", \"Domain-specific fine-tuning\", \"Evaluation challenges\"],\n",
    "  \"publication_date\": \"2024-01-19\"\n",
    "}\n",
    "\n",
    "medusa = {\n",
    "  \"title\": \"MEDUSA: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads\",\n",
    "  \"authors\": [\"Tianle Cai\", \"Yuhong Li\", \"Zhengyang Geng\", \"...\"],\n",
    "  \"affiliations\": [\"Princeton University\", \"University of Illinois Urbana-Champaign\", \"Carnegie Mellon University\", \"...\"],\n",
    "  \"focus\": \"Accelerating LLM inference with MEDUSA method\",\n",
    "  \"key_concepts\": [\"Multiple decoding heads\", \"Tree-based attention mechanism\", \"Fine-tuning strategies\"],\n",
    "  \"results\": \"Significant speedup in LLM inference with minimal quality compromise\",\n",
    "  \"publication_date\": \"2024-01-19\"\n",
    "}\n",
    "\n",
    "antisemitic_detection = {\n",
    "  \"title\": \"Detection of Emerging Coded Antisemitic Terminology in Online Posts\",\n",
    "  \"authors\": [\"Dhanush Kikkisetti\", \"Raza Ul Mustafa\", \"Wendy Melillo\", \"...\"],\n",
    "  \"affiliation\": \"American University\",\n",
    "  \"focus\": \"Detecting coded antisemitic terminology in social media posts\",\n",
    "  \"methodology\": [\"Extraction of trending terms\", \"Comparison with known terms\", \"Fine-tuning BERT model\"],\n",
    "  \"key_findings\": \"Identification of new antisemitic terms and development of methodologies for their detection\",\n",
    "  \"publication_date\": \"2024-01-19\"\n",
    "}\n",
    "\n",
    "jailbreak_resistance = {\n",
    "  \"title\": \"Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning\",\n",
    "  \"authors\": [\"Adib Hasan\", \"Ileana Rugina\", \"Alex Wang\"],\n",
    "  \"affiliation\": \"Massachusetts Institute of Technology (MIT)\",\n",
    "  \"focus\": \"Examining effects of pruning on LLM safety against jailbreaking prompts\",\n",
    "  \"methodology\": \"Comparative analysis using a new dataset of malicious tasks\",\n",
    "  \"key_findings\": \"Pruning can increase resistance to jailbreaking prompts\",\n",
    "  \"publication_date\": \"2024-01-19\"\n",
    "}\n",
    "\n",
    "rl_for_qa = {\n",
    "  \"title\": \"Reinforcement Learning for Question Answering in Programming Domain Using Public Community Scoring as Human Feedback\",\n",
    "  \"authors\": [\"Alexey Gorbatovski\", \"Sergey Kovalchuk\"],\n",
    "  \"affiliations\": [\"ITMO University\", \"Huawei\"],\n",
    "  \"focus\": \"Enhancing GPT Neo 125M's performance in Community QA through RLHF\",\n",
    "  \"methodology\": [\"Use of RLHF with community scoring\", \"Fine-tuning with Proximal Policy Optimization\"],\n",
    "  \"key_insights\": \"Limitations of traditional metrics for programming QA and need for domain-specific evaluation methods\",\n",
    "  \"publication_date\": \"2024-01-19\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pdfs('arxiv_pdfs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('dbkshack': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08f1c185a11ec3bb7ec5e07ee737b42c8afcf80b878d81e864da17ed0d390b00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
