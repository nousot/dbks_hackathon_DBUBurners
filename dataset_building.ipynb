{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mining_qa_prompts = {\n",
    "  \"title\": \"Q&A Prompts: Discovering Rich Visual Clues through Mining Question-Answer Prompts for VQA Requiring Diverse World Knowledge\",\n",
    "  \"authors\": [\"Haibo Wang\", \"Weifeng Ge\", \"...\"],\n",
    "  \"affiliation\": \"School of Computer Science, Fudan University\",\n",
    "  \"focus\": \"Enhancing AI models for Visual Question Answering using Q&A Prompts method\",\n",
    "  \"methodology\": [\"Training a visual question generation model\", \"Generating question-answer prompts\", \"Reasoning with these prompts\"],\n",
    "  \"key_findings\": \"Improvement in AI's ability to answer complex visual questions with diverse world knowledge\",\n",
    "  \"publication_date\": \"2024-01-19\"\n",
    "}\n",
    "\n",
    "clinical_document_qa = {\n",
    "  \"title\": \"Dynamic Q&A of Clinical Documents with Large Language Models\",\n",
    "  \"authors\": [\"Ran Elgedawy\", \"Sudarshan Srinivasan\", \"Ioana Danciu\", \"...\"],\n",
    "  \"affiliation\": \"University of Tennessee Knoxville, Oak Ridge National Laboratory\",\n",
    "  \"focus\": \"Development of a conversational interface using LLMs for querying clinical notes\",\n",
    "  \"key_technologies\": [\"Large Language Models\", \"Semantic Embedding Models\"],\n",
    "  \"applications\": \"Efficient querying and retrieval in EHRs\",\n",
    "  \"challenges_future_work\": [\"Model optimization\", \"Domain-specific fine-tuning\", \"Evaluation challenges\"],\n",
    "  \"publication_date\": \"2024-01-19\"\n",
    "}\n",
    "\n",
    "medusa = {\n",
    "  \"title\": \"MEDUSA: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads\",\n",
    "  \"authors\": [\"Tianle Cai\", \"Yuhong Li\", \"Zhengyang Geng\", \"...\"],\n",
    "  \"affiliations\": [\"Princeton University\", \"University of Illinois Urbana-Champaign\", \"Carnegie Mellon University\", \"...\"],\n",
    "  \"focus\": \"Accelerating LLM inference with MEDUSA method\",\n",
    "  \"key_concepts\": [\"Multiple decoding heads\", \"Tree-based attention mechanism\", \"Fine-tuning strategies\"],\n",
    "  \"results\": \"Significant speedup in LLM inference with minimal quality compromise\",\n",
    "  \"publication_date\": \"2024-01-19\"\n",
    "}\n",
    "\n",
    "antisemitic_detection = {\n",
    "  \"title\": \"Detection of Emerging Coded Antisemitic Terminology in Online Posts\",\n",
    "  \"authors\": [\"Dhanush Kikkisetti\", \"Raza Ul Mustafa\", \"Wendy Melillo\", \"...\"],\n",
    "  \"affiliation\": \"American University\",\n",
    "  \"focus\": \"Detecting coded antisemitic terminology in social media posts\",\n",
    "  \"methodology\": [\"Extraction of trending terms\", \"Comparison with known terms\", \"Fine-tuning BERT model\"],\n",
    "  \"key_findings\": \"Identification of new antisemitic terms and development of methodologies for their detection\",\n",
    "  \"publication_date\": \"2024-01-19\"\n",
    "}\n",
    "\n",
    "jailbreak_resistance = {\n",
    "  \"title\": \"Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning\",\n",
    "  \"authors\": [\"Adib Hasan\", \"Ileana Rugina\", \"Alex Wang\"],\n",
    "  \"affiliation\": \"Massachusetts Institute of Technology (MIT)\",\n",
    "  \"focus\": \"Examining effects of pruning on LLM safety against jailbreaking prompts\",\n",
    "  \"methodology\": \"Comparative analysis using a new dataset of malicious tasks\",\n",
    "  \"key_findings\": \"Pruning can increase resistance to jailbreaking prompts\",\n",
    "  \"publication_date\": \"2024-01-19\"\n",
    "}\n",
    "\n",
    "rl_for_qa = {\n",
    "  \"title\": \"Reinforcement Learning for Question Answering in Programming Domain Using Public Community Scoring as Human Feedback\",\n",
    "  \"authors\": [\"Alexey Gorbatovski\", \"Sergey Kovalchuk\"],\n",
    "  \"affiliations\": [\"ITMO University\", \"Huawei\"],\n",
    "  \"focus\": \"Enhancing GPT Neo 125M's performance in Community QA through RLHF\",\n",
    "  \"methodology\": [\"Use of RLHF with community scoring\", \"Fine-tuning with Proximal Policy Optimization\"],\n",
    "  \"key_insights\": \"Limitations of traditional metrics for programming QA and need for domain-specific evaluation methods\",\n",
    "  \"publication_date\": \"2024-01-19\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 raw  \\\n",
      "0  Dynamic Q&A of Clinical Documents with Large\\n...   \n",
      "1  Pruning for Protection: Increasing Jailbreak\\n...   \n",
      "2  MEDUSA : Simple LLM Inference Acceleration\\nFr...   \n",
      "3  Using LLMs to discover emerging coded antisemi...   \n",
      "4  Reinforcement learning for question answering ...   \n",
      "\n",
      "                                          structured  \n",
      "0  {'title': 'Dynamic Q&A of Clinical Documents w...  \n",
      "1  {'title': 'Pruning for Protection: Increasing ...  \n",
      "2  {'title': 'MEDUSA: Simple LLM Inference Accele...  \n",
      "3  {'title': 'Detection of Emerging Coded Antisem...  \n",
      "4  {'title': 'Reinforcement Learning for Question...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import pandas as pd\n",
    "\n",
    "def load_pdfs(dir_path: str) -> Dict[str, str]:\n",
    "    file_contents = {}\n",
    "    files = [f for f in os.listdir(dir_path) if f.endswith('.pdf')]\n",
    "    for file in files:\n",
    "        loader = PyPDFLoader(os.path.join(dir_path, file))\n",
    "        pages = loader.load_and_split()\n",
    "        full_text = ' '.join([page.page_content for page in pages])  # Extracting page_content from each Document object\n",
    "        file_contents[file] = full_text\n",
    "    return file_contents\n",
    "\n",
    "dir_path = \"arxiv_pdfs\"\n",
    "\n",
    "pdf_contents = load_pdfs(dir_path)\n",
    "\n",
    "structured_data = {\n",
    "    \"mining_qa_prompt.pdf\": mining_qa_prompts,\n",
    "    \"clinical_document_qa.pdf\": clinical_document_qa,\n",
    "    \"medusa.pdf\": medusa,\n",
    "    \"antisemitic_detection.pdf\": antisemitic_detection,\n",
    "    \"jailbreak_resistance.pdf\": jailbreak_resistance,\n",
    "    \"rl_for_qa.pdf\": rl_for_qa\n",
    "}\n",
    "\n",
    "df_list = []\n",
    "for file_name, raw_content in pdf_contents.items():\n",
    "    structured_info = structured_data.get(file_name, {})\n",
    "    df_list.append({'raw': raw_content, 'structured': structured_info})\n",
    "\n",
    "combined_df = pd.DataFrame(df_list)\n",
    "combined_df.to_csv('arxiv_pdfs_data', index=False)\n",
    "\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2401.10712.pdf': {'title': 'Q&A Prompts: Discovering Rich Visual Clues through Mining Question-Answer Prompts for VQA Requiring Diverse World Knowledge', 'authors': ['Haibo Wang', 'Weifeng Ge', '...'], 'affiliation': 'School of Computer Science, Fudan University', 'focus': 'Enhancing AI models for Visual Question Answering using Q&A Prompts method', 'methodology': ['Training a visual question generation model', 'Generating question-answer prompts', 'Reasoning with these prompts'], 'key_findings': \"Improvement in AI's ability to answer complex visual questions with diverse world knowledge\", 'publication_date': '2024-01-19'}, '2401.10733.pdf': {'title': 'Dynamic Q&A of Clinical Documents with Large Language Models', 'authors': ['Ran Elgedawy', 'Sudarshan Srinivasan', 'Ioana Danciu', '...'], 'affiliation': 'University of Tennessee Knoxville, Oak Ridge National Laboratory', 'focus': 'Development of a conversational interface using LLMs for querying clinical notes', 'key_technologies': ['Large Language Models', 'Semantic Embedding Models'], 'applications': 'Efficient querying and retrieval in EHRs', 'challenges_future_work': ['Model optimization', 'Domain-specific fine-tuning', 'Evaluation challenges'], 'publication_date': '2024-01-19'}, '2401.10774.pdf': {'title': 'MEDUSA: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads', 'authors': ['Tianle Cai', 'Yuhong Li', 'Zhengyang Geng', '...'], 'affiliations': ['Princeton University', 'University of Illinois Urbana-Champaign', 'Carnegie Mellon University', '...'], 'focus': 'Accelerating LLM inference with MEDUSA method', 'key_concepts': ['Multiple decoding heads', 'Tree-based attention mechanism', 'Fine-tuning strategies'], 'results': 'Significant speedup in LLM inference with minimal quality compromise', 'publication_date': '2024-01-19'}, '2401.10841.pdf': {'title': 'Detection of Emerging Coded Antisemitic Terminology in Online Posts', 'authors': ['Dhanush Kikkisetti', 'Raza Ul Mustafa', 'Wendy Melillo', '...'], 'affiliation': 'American University', 'focus': 'Detecting coded antisemitic terminology in social media posts', 'methodology': ['Extraction of trending terms', 'Comparison with known terms', 'Fine-tuning BERT model'], 'key_findings': 'Identification of new antisemitic terms and development of methodologies for their detection', 'publication_date': '2024-01-19'}, '2401.10862.pdf': {'title': 'Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning', 'authors': ['Adib Hasan', 'Ileana Rugina', 'Alex Wang'], 'affiliation': 'Massachusetts Institute of Technology (MIT)', 'focus': 'Examining effects of pruning on LLM safety against jailbreaking prompts', 'methodology': 'Comparative analysis using a new dataset of malicious tasks', 'key_findings': 'Pruning can increase resistance to jailbreaking prompts', 'publication_date': '2024-01-19'}, '2401.10882.pdf': {'title': 'Reinforcement Learning for Question Answering in Programming Domain Using Public Community Scoring as Human Feedback', 'authors': ['Alexey Gorbatovski', 'Sergey Kovalchuk'], 'affiliations': ['ITMO University', 'Huawei'], 'focus': \"Enhancing GPT Neo 125M's performance in Community QA through RLHF\", 'methodology': ['Use of RLHF with community scoring', 'Fine-tuning with Proximal Policy Optimization'], 'key_insights': 'Limitations of traditional metrics for programming QA and need for domain-specific evaluation methods', 'publication_date': '2024-01-19'}}\n"
     ]
    }
   ],
   "source": [
    "print(structured_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('dbkshack': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08f1c185a11ec3bb7ec5e07ee737b42c8afcf80b878d81e864da17ed0d390b00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
